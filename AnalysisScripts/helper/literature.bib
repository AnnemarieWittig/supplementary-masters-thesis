@inproceedings{neuralCodeCompletion,
author = {Ziegler, Albert and Kalliamvakou, Eirini and Li, X. Alice and Rice, Andrew and Rifkin, Devon and Simister, Shawn and Sittampalam, Ganesh and Aftandilian, Edward},
title = {Productivity assessment of neural code completion},
year = {2022},
isbn = {9781450392730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3520312.3534864},
doi = {10.1145/3520312.3534864},
abstract = {Neural code synthesis has reached a point where snippet generation is accurate enough to be considered for integration into human software development workflows. Commercial products aim to increase programmers’ productivity, without being able to measure it directly. In this case study, we asked users of GitHub Copilot about its impact on their productivity, and sought to find a reflection of their perception in directly measurable user data. We find that the rate with which shown suggestions are accepted, rather than more specific metrics regarding the persistence of completions in the code over time, drives developers’ perception of productivity.},
booktitle = {Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming},
pages = {21–29},
numpages = {9},
keywords = {code completion, code synthesis, neural networks, productivity},
location = {San Diego, CA, USA},
series = {MAPS 2022}
}



@article{kinsley,
  title={Unleashing developer productivity with generative AI},
  author={Deniz, Begum Karaci and Gnanasambandam, Chandra and Harrysson, Martin and Hussin, Alharith and Srivastava, Shivam},
  journal={McKinsey \& Company},
  year={2023},
  month={June},
  url={https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/unleashing-developer-productivity-with-generative-ai}
}
@misc{dohmke2023seachangesoftwaredevelopment,
      title={Sea Change in Software Development: Economic and Productivity Analysis of the AI-Powered Developer Lifecycle}, 
      author={Thomas Dohmke and Marco Iansiti and Greg Richards},
      year={2023},
      eprint={2306.15033},
      archivePrefix={arXiv},
      primaryClass={econ.GN},
doi = {10.48550/arXiv.2306.15033},
      url={https://arxiv.org/abs/2306.15033}, 
}
@inproceedings{solohubov2023accelerating,
author    = {Illia Solohubov and Artur Moroz and Mariia Yu. Tiahunova and Halyna H. Kyrychek and Stepan Skrupsky},
title     = {Accelerating software development with AI: exploring the impact of ChatGPT and GitHub Copilot},
booktitle = {CTE 2023: 11th Workshop on Cloud Technologies in Education},
year      = {2023},
date      = {2023-12-22},
location  = {Kryvyi Rih, Ukraine},
pages     = {186--194},
publisher = {CEUR-WS.org},
volume    = {3679},
url       = {https://ceur-ws.org/Vol-3679/paper17.pdf},
authorinfo = {
1National University “Zaporizhzhya Polytechnic”, 64 Zhukovskyi Str., Zaporizhzhya, 69063, Ukraine
Emails: illia.solohubov@gmail.com (I. Solohubov); arthur.official.moroz@gmail.com (A. Moroz); mary.tyagunova@gmail.com (M. Yu. Tiahunova); kirgal08@gmail.com (H. H. Kyrychek)
ORCIDs: 0009-0000-6140-3485 (I. Solohubov); 0009-0008-6742-2298 (A. Moroz); 0000-0002-9166-5897 (M. Yu. Tiahunova); 0000-0002-9437-9095 (S. Skrupsky)
},
note      = {Available at: \url{https://ceur-ws.org/Vol-3679/paper17.pdf}}
}

@article{perceivedimpactofaibasedtooling,
abstract = {Artificial intelligence (AI) is a powerful tool that can play a crucial role in software development. The integration of AI in that domain has allowed various AI-powered tools to emerge and have the potential to positively impact code quality. This article explores the perceived impact of AI tools on the quality of software development code. Through a survey conducted in various tech companies, the findings of this study aimed to provide a comprehensive understanding of the current state and potential future trends of artificial intelligence in software engineering. The overall results show that there is high satisfaction among developers using AI tools, with more than three-quarters of them stating that the adoption of these tools positively impacted their overall satisfaction and productivity in the software development sector. Although there are relatively mediocre values in terms of grades in development satisfaction with readability, maintainability, efficiency, and precision, there is an overall positive perceived outlook for AI tools. There is room for growth in both adoption and refinement, especially when talking about developer-centric tools.},
author = {Martinovi{\'c}, Boris and Rozi{\'c}, Robert},
date = {2025/01/06},
date-added = {2025-05-20 09:43:21 +0200},
date-modified = {2025-05-20 09:43:51 +0200},
doi = {10.1007/s42979-024-03608-4},
id = {Martinovi{\'c}2025},
isbn = {2661-8907},
journal = {SN Computer Science},
number = {1},
pages = {63},
title = {Perceived Impact of AI-Based Tooling on Software Development Code Quality},
url = {https://doi.org/10.1007/s42979-024-03608-4},
volume = {6},
year = {2025},
bdsk-url-1 = {https://doi.org/10.1007/s42979-024-03608-4}}

@misc{borg2024doescodevelopmentaiassistants,
title={Does Co-Development with AI Assistants Lead to More Maintainable Code? A Registered Report},
author={Markus Borg and Dave Hewett and Donald Graham and Noric Couderc and Emma Söderberg and Luke Church and Dave Farley},
year={2024},
eprint={2408.10758},
archivePrefix={arXiv},
primaryClass={cs.SE},
url={https://arxiv.org/abs/2408.10758},
}
@inproceedings{agrarsurvey,
author = {Davila, Nicole and Wiese, Igor and Steinmacher, Igor and Lucio da Silva, Lucas and Kawamoto, Andre and Favaro, Gilson Jose Peres and Nunes, Ingrid},
title = {An Industry Case Study on Adoption of AI-based Programming Assistants},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3643648},
doi = {10.1145/3639477.3643648},
abstract = {Programming assistants based on artificial intelligence (AI), such as ChatGPT and GitHub Copilot, have gained worldwide popularity recently. Studies in software development have explored the adoption of these tools, investigating their characteristics and impacts and how practitioners interact and perceive them. To contribute to this growing body of knowledge, in this study, we aim to explore the adoption of AI-based programming assistants in the Brazilian industry. More specifically, we aim to understand how practitioners of a particular Brazilian agroindustry-related company perceive and use AI-based tools to develop software. Using an online survey, we collected and analyzed 72 responses from employees of the studied company. Our findings suggest that practitioners mainly adopt ChatGPT and GitHub Copilot, interacting with these tools to accelerate online searching, typing, and syntax recall. A recurrent difficulty is the lack of context in the suggestions provided by these tools, but participants work on detailed descriptions to contextualize and cope with this challenge. Among the reasons for not using AI-based tools, the most influential is that participants use a commercial programming language, i.e., Uniface, which these tools lack examples. Our results provide insights into the state of the practice related to AI-based programming assistants and discuss implications for practitioners and researchers.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {92–102},
numpages = {11},
keywords = {artificial intelligence, generative AI, ChatGPT, industry case study, software development},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@inproceedings{stackspot,
author = {Pinto, Gustavo and De Souza, Cleidson and Rocha, Thayssa and Steinmacher, Igor and Souza, Alberto and Monteiro, Edward},
title = {Developer Experiences with a Contextualized AI Coding Assistant: Usability, Expectations, and Outcomes},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644949},
doi = {10.1145/3644815.3644949},
abstract = {In the rapidly advancing field of artificial intelligence, software development has emerged as a key area of innovation. Despite the plethora of general-purpose AI assistants available, their effectiveness diminishes in complex, domain-specific scenarios. Noting this limitation, both the academic community and industry players are relying on contextualized coding AI assistants. These assistants surpass general-purpose AI tools by integrating proprietary, domain-specific knowledge, offering precise and relevant solutions. Our study focuses on the initial experiences of 62 participants who used a contextualized coding AI assistant --- named StackSpot AI--- in a controlled setting. According to the participants, the assistants' use resulted in significant time savings, easier access to documentation, and the generation of accurate codes for internal APIs. However, challenges associated with the knowledge sources necessary to make the coding assistant access more contextual information as well as variable responses and limitations in handling complex codes were observed. The study's findings, detailing both the benefits and challenges of contextualized AI assistants, underscore their potential to revolutionize software development practices, while also highlighting areas for further refinement.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {81–91},
numpages = {11},
keywords = {LLM, LLM-based applications, user expectations, perception of productivity},
location = {Lisbon, Portugal},
series = {CAIN '24}
}
@misc{ibmllm,
title={Examining the Use and Impact of an AI Code Assistant on Developer Productivity and Experience in the Enterprise},
author={Justin D. Weisz and Shraddha Kumar and Michael Muller and Karen-Ellen Browne and Arielle Goldberg and Ellice Heintze and Shagun Bajpai},
year={2025},
eprint={2412.06603},
archivePrefix={arXiv},
primaryClass={cs.HC},
url={https://arxiv.org/abs/2412.06603},
}


@misc{StackOverflow2024,
author = {{Stack Overflow}},
title = {{Stack Overflow Developer Survey 2024. AI}},
url = {https://insights.stackoverflow.com/survey/2020#technology-most-loved-dreaded-and-wanted-languages-dreaded},
urldate = {2021-05-02},
year = {2020}
}

@misc{shin2025promptengineeringfinetuningempirical,
title={Prompt Engineering or Fine-Tuning: An Empirical Assessment of LLMs for Code},
author={Jiho Shin and Clark Tang and Tahmineh Mohati and Maleknaz Nayebi and Song Wang and Hadi Hemmati},
year={2025},
eprint={2310.10508},
archivePrefix={arXiv},
primaryClass={cs.SE},
url={https://arxiv.org/abs/2310.10508},
}
@article{ANZBankExperiment,
title={The Impact of AI Tool on Engineering at ANZ Bank An Emperical Study on GitHub Copilot within Coporate Environment},
author={Sayan Chatterjee and Ching Louis Liu and Gareth Rowland and Tim Hogarth},
journal={ArXiv},
year={2024},
volume={abs/2402.05636},
url={https://api.semanticscholar.org/CorpusID:267547947}
}
@ARTICLE{devperceptions,
author = {{Vaillant}, Thiago S. and {Deveza de Almeida}, Felipe and {Neto}, Paulo Anselmo M.~S. and {Gao}, Cuiyun and {Bosch}, Jan and {Santana de Almeida}, Eduardo},
title = "{Developers' Perceptions on the Impact of ChatGPT in Software Development: A Survey}",
journal = {arXiv e-prints},
keywords = {Computer Science - Software Engineering, D.2.0},
year = 2024,
month = may,
eid = {arXiv:2405.12195},
pages = {arXiv:2405.12195},
doi = {10.48550/arXiv.2405.12195},
archivePrefix = {arXiv},
eprint = {2405.12195},
primaryClass = {cs.SE},
adsurl = {https://ui.adsabs.harvard.edu/abs/2024arXiv240512195V},
adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{BeyondCodeGen,
author = {Khojah, Ranim and Mohamad, Mazen and Leitner, Philipp and de Oliveira Neto, Francisco Gomes},
title = {Beyond Code Generation: An Observational Study of ChatGPT Usage in Software Engineering Practice},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660788},
doi = {10.1145/3660788},
abstract = {Large Language Models (LLMs) are frequently discussed in academia and the general public as support tools for virtually any use case that relies on the production of text, including software engineering. Currently, there is much debate, but little empirical evidence, regarding the practical usefulness of LLM-based tools such as ChatGPT for engineers in industry. We conduct an observational study of 24 professional software engineers who have been using ChatGPT over a period of one week in their jobs, and qualitatively analyse their dialogues with the chatbot as well as their overall experience (as captured by an exit survey). We find that rather than expecting ChatGPT to generate ready-to-use software artifacts (e.g., code), practitioners more often use ChatGPT to receive guidance on how to solve their tasks or learn about a topic in more abstract terms. We also propose a theoretical framework for how the (i) purpose of the interaction, (ii) internal factors (e.g., the user's personality), and (iii) external factors (e.g., company policy) together shape the experience (in terms of perceived usefulness and trust). We envision that our framework can be used by future research to further the academic discussion on LLM usage by software engineering practitioners, and to serve as a reference point for the design of future empirical LLM research in this domain.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {81},
numpages = {22},
keywords = {Chatbots, Large Language Models (LLMs), Software Development Bots}
}
@misc{peng2023impactaideveloperproductivity,
title={The Impact of AI on Developer Productivity: Evidence from GitHub Copilot},
author={Sida Peng and Eirini Kalliamvakou and Peter Cihon and Mert Demirer},
year={2023},
eprint={2302.06590},
archivePrefix={arXiv},
primaryClass={cs.SE},
url={https://arxiv.org/abs/2302.06590},
doi = {10.48550/arXiv.2302.06590}
}
@article{copilotimpact, author = {Ziegler, Albert and Kalliamvakou, Eirini and Li, X. Alice and Rice, Andrew and Rifkin, Devon and Simister, Shawn and Sittampalam, Ganesh and Aftandilian, Edward}, title = {Measuring GitHub Copilot's Impact on Productivity}, year = {2024}, issue_date = {March 2024}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {67}, number = {3}, issn = {0001-0782}, url = {https://doi.org/10.1145/3633453}, doi = {10.1145/3633453}, abstract = {Case study asks Copilot users about its impact on their productivity, and seeks to find their perceptions mirrored in user data.}, journal = {Commun. ACM}, month = feb, pages = {54–63}, numpages = {10} }
@article{takingFlight,
author = {Bird, Christian and Ford, Denae and Zimmermann, Thomas and Forsgren, Nicole and Kalliamvakou, Eirini and Lowdermilk, Travis and Gazit, Idan},
title = {Taking Flight with Copilot: Early insights and opportunities of AI-powered pair-programming tools},
year = {2023},
issue_date = {November/December},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {6},
issn = {1542-7730},
url = {https://doi.org/10.1145/3582083},
doi = {10.1145/3582083},
abstract = {Over the next five years, AI-powered tools likely will be helping developers in many diverse tasks. For example, such models may be used to improve code review, directing reviewers to parts of a change where review is most needed or even directly providing feedback on changes. Models such as Codex may suggest fixes for defects in code, build failures, or failing tests. These models are able to write tests automatically, helping to improve code quality and downstream reliability of distributed systems. This study of Copilot shows that developers spend more time reviewing code than actually writing code. As AI-powered tools are integrated into more software development tasks, developer roles will shift so that more time is spent assessing suggestions related to the task than doing the task itself.},
journal = {Queue},
month = jan,
pages = {35–57},
numpages = {23}
}
@inproceedings{largeScaleSurveyOnUsability,
author = {Liang, Jenny T. and Yang, Chenyang and Myers, Brad A.},
title = {A Large-Scale Survey on the Usability of AI Programming Assistants: Successes and Challenges},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3608128},
doi = {10.1145/3597503.3608128},
abstract = {The software engineering community recently has witnessed widespread deployment of AI programming assistants, such as GitHub Copilot. However, in practice, developers do not accept AI programming assistants' initial suggestions at a high frequency. This leaves a number of open questions related to the usability of these tools. To understand developers' practices while using these tools and the important usability challenges they face, we administered a survey to a large population of developers and received responses from a diverse set of 410 developers. Through a mix of qualitative and quantitative analyses, we found that developers are most motivated to use AI programming assistants because they help developers reduce key-strokes, finish programming tasks quickly, and recall syntax, but resonate less with using them to help brainstorm potential solutions. We also found the most important reasons why developers do not use these tools are because these tools do not output code that addresses certain functional or non-functional requirements and because developers have trouble controlling the tool to generate the desired output. Our findings have implications for both creators and users of AI programming assistants, such as designing minimal cognitive effort interactions with these tools to reduce distractions for users while they are programming.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {52},
numpages = {13},
keywords = {AI programming assistants, usability study},
location = {Lisbon, Portugal},
series = {ICSE '24}
}
@article{interviews, title={An Empirical Study of Adoption of ChatGPT for Bug Fixing among Professional Developers}, volume={1}, url={https://bergersci.com/index.php/jta/article/view/19}, DOI={10.61187/ita.v1i1.19}, abstractNote={&lt;p&gt;ChatGPT is a powerful tool that assists software engineers in identifying and rectifying errors in code. One of its primary advantages is its ability to engage in natural language conversation with humans, which allows it to collaborate more closely with engineers in improving and optimizing the code. However, despite its potential advantages, software developers do not always utilize ChatGPT as a tool for bug fixing. In this study, we aim to examine the factors that influence the adoption of ChatGPT for bug fixing among professional software developers, based on the Unified Theory of Acceptance and Use of Technology (UTAUT) theory. To accomplish this, we conducted 50 semi-structured interviews with professional software developers and other stakeholders. Our findings indicate that the performance expectancy and effort expectancy of professional software developers, as well as social influence, facilitating conditions, data security, and trust are the key factors of adoption. These findings suggest that understanding these factors can be critical in promoting the adoption and use of ChatGPT in the software development industry.&lt;/p&gt;}, number={1}, journal={Innovation & Technology Advances}, author={Ge, Haotong and Wu, Yuemeng}, year={2023}, month={Jun.}, pages={21–29} }
@article{groundedCopilot,
author = {Barke, Shraddha and James, Michael B. and Polikarpova, Nadia},
title = {Grounded Copilot: How Programmers Interact with Code-Generating Models},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3586030},
doi = {10.1145/3586030},
abstract = {Powered by recent advances in code-generating models, AI assistants like Github Copilot promise to change the face of programming forever. But what is this new face of programming? We present the first grounded theory analysis of how programmers interact with Copilot, based on observing 20 participants—with a range of prior experience using the assistant—as they solve diverse programming tasks across four languages. Our main finding is that interactions with programming assistants are bimodal: in acceleration mode, the programmer knows what to do next and uses Copilot to get there faster; in exploration mode, the programmer is unsure how to proceed and uses Copilot to explore their options. Based on our theory, we provide recommendations for improving the usability of future AI programming assistants.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {78},
numpages = {27},
keywords = {AI Assistants, Grounded Theory, Program Synthesis}
}