= Analysis Outputs

This directory contains the output files generated by the analysis scripts in the link:../AnalysisScripts/[AnalysisScripts] directory. The results are organized by industry and open-source repositories, providing both the bucketed metric values as CSV files and some PDF visualizations used in the thesis.


Note that usually, the final anonymization of participants' study-IDs is only done for visualizations and in the final steps. The intermediate results usually are not yet cleaned. The ones shared here have been manually cleaned by me as to not store the IDs of participants publically.

== Directory Structure

The outputs are organized into subdirectories based on:

- **Type**: Repository-level analysis (OSRs) vs. person-level analysis (IR)
- **Bucket size**: Time period aggregation (14 days vs. 90 days)

== Directory contents
The two output directories contain the analysis results for open source repositories with 90-day time buckets and per-person analysis of industry repositories with 14-day buckets, including:

**Commit-based Metrics:**

- `commits_total_per_XX_days.csv` - Total number of commits per 90-day period
- `commits_loc_added_per_XX_days.csv` - Lines of code added per commit
- `commits_loc_deleted_per_XX_days.csv` - Lines of code deleted per commit  
- `commits_loc_changed_per_XX_days.csv` - Total lines of code changed
- `commits_coupling_per_XX_days.csv` - Files changed per Commit

**File-level-based Metrics:**

- `M1_per_XX_days.csv` - Relative churn method 1 ((LoCm + LoCa) / file length)
- `M2_per_XX_days.csv` - Relative churn method 2 (deleted/file length)
- `M7_per_XX_days.csv` - Relative churn method 7 ((LoCm + LoCa)/ LoCd)

**Pull Request-based Metrics:**

- `pull_requests_total_per_XX_days.csv` - Total number of pull requests
- `pull_requests_successful_per_XX_days.csv` - Successful PR completion rates
- `pull_requests_time_to_close_per_XX_days.csv` - Time from PR creation to closure
- `pull_requests_time_to_merge_per_XX_days.csv` - Time from PR creation to merge

**Other Metrics:**

- `releases_per_XX_days.csv` - Number of releases per time period
- `time_to_merge_into_main_per_XX_days.csv` - Time to merge into main branch

**A comprehensive explanation of each of the metrics can be found in the thesis.**


== Usage Notes

=== Reading the CSV files

- **Pre/Post Analysis**: Each metric is split into pre-introduction and post-introduction periods
- **Bucket Numbering**: Higher bucket numbers represent more recent time period, i.e. pre-0 is the first bucket, starting with the specified starting day to the analysis. The highest pre-X is the last bucket before the AI tool's introduction. It ends with the day before the introduction day, before post-0 indicates the first bucket after and including the introduction day.
- **Missing Data**: Empty cells indicate no data available for that time period

=== Reproducing Results
To regenerate these outputs:

1. Ensure you have the required data in the expected format
2. Configure the `.env` file in the AnalysisScripts directory
3. Run the corresponding analysis notebooks
4. Results will be automatically saved to subdirectories based on your environment file

== Integration with Thesis

These output files serve as the primary data source for:
- Analysis results presented in the thesis
- Figures and tables showing productivity impacts
- Comparative analysis between different development contexts (OSR vs individual projects)

The results demonstrate the productivity impacts of developers using LLM-based coding assistance and inform the hypothesis used to answer this thesis' research questions.
